{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b57d61-7d64-4df4-9955-d3e084d1d13e",
   "metadata": {},
   "source": [
    "# Baseline experiment \n",
    "\n",
    "The output of the first assessment of a pair is used as predicton for the second assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93690545-91be-41ac-98f2-392b44e3c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import targets, get_feature_sets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X = pd.read_pickle('data/cached_X_imputed.pckl')\n",
    "y = pd.read_pickle('data/cached_y.pckl')\n",
    "feature_sets = get_feature_sets(X)\n",
    "df = pd.read_pickle('data/cached_df.pckl')\n",
    "\n",
    "ys_train, ys_test = [], []\n",
    "lastrow = None\n",
    "\n",
    "patient_ids = df.BALANCE_ID.unique()\n",
    "for patient_id in patient_ids:\n",
    "    pdf = df[df.BALANCE_ID == patient_id]\n",
    "    for i in range(0, pdf.shape[0] - 1):\n",
    "        for j in range(i+1, pdf.shape[0]):\n",
    "            assessment0 = pdf.iloc[i].copy()\n",
    "            assessment1 = pdf.iloc[j]\n",
    "            \n",
    "            time_diff = assessment1['Assessment_date_days'] - assessment0['Assessment_date_days']\n",
    "            assessment0['time_diff'] = time_diff;\n",
    "            \n",
    "            # THIS IS THE ONLY CHANGE IN THIS NOTEBOOK COMPARED TO COMMON PREPROCESSING.\n",
    "            ys_train.append(assessment0[['BALANCE_ID'] + targets])\n",
    "            ys_test.append(assessment1[['BALANCE_ID'] + targets])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85202f-8ad7-4d42-a1fa-4c09f27f0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrames\n",
    "y_train = pd.DataFrame(ys_train).reset_index(drop=True)\n",
    "y_test = pd.DataFrame(ys_test).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f53838-9e20-4cf3-9cad-53f46071da5e",
   "metadata": {},
   "source": [
    "### This baseline assumes that T0==T1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93651951-7c7f-4230-91ca-84d977c17fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "results_LOCF = {}\n",
    "n_bootstraps = 1000\n",
    "rng = np.random.RandomState(42)  # For reproducibility\n",
    "\n",
    "for target in targets:\n",
    "    # Extract true labels and predicted probabilities for the target\n",
    "    true_labels = y_test[target].astype(int)\n",
    "    predicted_scores = y_train[target].astype(float)  # LOCF assumption\n",
    "\n",
    "    # Calculate the base AUC\n",
    "    auc_value = roc_auc_score(true_labels, predicted_scores)\n",
    "\n",
    "    # Bootstrap AUCs\n",
    "    bootstrapped_scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sample indices\n",
    "        indices = rng.randint(0, len(predicted_scores), len(predicted_scores))\n",
    "        if len(np.unique(true_labels.iloc[indices])) < 2:\n",
    "            continue  # Skip if only one class in sample\n",
    "        auc = roc_auc_score(true_labels.iloc[indices], predicted_scores.iloc[indices])\n",
    "        bootstrapped_scores.append(auc)\n",
    "\n",
    "    # Compute 95% confidence interval\n",
    "    ci_lower, ci_upper = np.percentile(bootstrapped_scores, [2.5, 97.5])\n",
    "\n",
    "    # Store results\n",
    "    results_LOCF[target] = {\n",
    "        \"Classifier\": \"LOCF\",\n",
    "        \"roc_auc\": {\n",
    "            \"mean\": auc_value,\n",
    "            \"95% CI\": (ci_lower, ci_upper)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"{target} - ROC AUC: {auc_value:.3f} (95% CI: {ci_lower:.3f} - {ci_upper:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f6fcb1-3e3c-4fb4-97e3-752d3fae88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for target, metrics in results_LOCF.items():\n",
    "    row = {\n",
    "        'Target': target,\n",
    "        'Classifier': metrics['Classifier']\n",
    "    }\n",
    "\n",
    "    if 'roc_auc' in metrics:\n",
    "        roc_auc = metrics['roc_auc']\n",
    "        row['roc_auc'] = round(roc_auc['mean'], 3)\n",
    "        row['roc_auc_ci_low'] = round(roc_auc['95% CI'][0], 3)\n",
    "        row['roc_auc_ci_high'] = round(roc_auc['95% CI'][1], 3)\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(rows)\n",
    "\n",
    "# Export to CSV\n",
    "results_df.to_csv('results_LOCF_AUC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ccfc9-ae8e-4880-b391-49ef09a1d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape[0] == y_train.shape[0] == y_test.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
