{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e53139f7-dfcb-4601-a71a-5a874ef9c2ec",
   "metadata": {},
   "source": [
    "# Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6e06f-dad2-4e05-9e18-fb578926b1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from constants import targets\n",
    "\n",
    "X = pd.read_pickle('data/external_x.pckl')\n",
    "y = pd.read_pickle('data/external_y.pckl')\n",
    "\n",
    "\n",
    "cols_to_convert = [\n",
    "    \"BMI\"\n",
    "]\n",
    "\n",
    "X[cols_to_convert] = X[cols_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Define the relevant columns\n",
    "frailty_columns = [\"C30_Q3\", \"C30_Q6\", \"C30_Q10\", \"C30_Q12\", \"C30_Q13\"]\n",
    "\n",
    "# Compute frailty score\n",
    "X[\"frailty_score\"] = X[frailty_columns].map(lambda x: 1 if x in [3, 4] else (0 if x in [1, 2] else np.nan)).sum(axis=1, skipna=False)\n",
    "\n",
    "# Assign \"Frail\" while keeping NAs\n",
    "X[\"Frail\"] = np.where(X[\"frailty_score\"].isna(), np.nan, np.where(X[\"frailty_score\"] >= 3, 1, 0))\n",
    "\n",
    "# Define populations based on dichotomous variables in X\n",
    "populations = {\n",
    "    'Menopause': X[X['Menopause'] == 1], # not in the data set, if only common denominator of all cohorts is taken \n",
    "    'Financial difficulties': X[X['C30_FI_class'] == 1],\n",
    "    'Obese': X[X['BMI'] >= 30],\n",
    "    'Comorbidities > 1': X[X['Comorbidities'] > 1],\n",
    "    'Lower educational status': X[(X['Education_status_1'] == 1) | (X['Education_status_2'] == 1)],\n",
    "    'Frail': X[X['Frail'] == 1],\n",
    "    'Future_assessment': X[X['time_diff'] >= 365 ], # for predicting assessments that are more than 12 month in the future\n",
    "    'After_diagnosis': X[X['Assessment_date_days'] <= 365 ], # for patients within the first 12 month after diagnosis where we expect the biggest changes\n",
    "    'Full external dataset': X\n",
    "}\n",
    "\n",
    "X.to_csv('data/external_validation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45844a-c604-498a-8861-61973f03919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in populations.items():\n",
    "    n_rows = len(df)\n",
    "    n_unique_balance_ids = df[\"BALANCE_ID\"].nunique()\n",
    "    print(f\"{name}: {n_rows} observations, {n_unique_balance_ids} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34162351-0f70-4ca1-81cb-15befa31b67f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(f\"\\n Evaluating performance for target: {target} \\n\")\n",
    "    for group_name, X_group in populations.items():\n",
    "        y_group = y.loc[X_group.index, target]  # Align indices and select the target column\n",
    "        n_rows = len(y_group)\n",
    "        n_events = (y_group == 1).sum()  # Assuming '1' indicates an event\n",
    "        event_rate = (n_events / n_rows) * 100 if n_rows > 0 else 0\n",
    "        print(f\"{group_name}: {n_events} events ({event_rate:.2f}% event rate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1265d-42a8-4124-9032-73b708463654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Build a dictionary of population summary strings per group.\n",
    "pop_summary = {}\n",
    "for name, df in populations.items():\n",
    "    n_rows = len(df)\n",
    "    n_unique_balance_ids = df[\"BALANCE_ID\"].nunique()\n",
    "    pop_summary[name] = f\"{n_rows} observations, {n_unique_balance_ids} patients\"\n",
    "\n",
    "# Initialize a list to collect rows for the final DataFrame.\n",
    "# The first row is the population summary row.\n",
    "rows = []\n",
    "\n",
    "# Create the first row: A special row with Target = \"Population Summary\"\n",
    "pop_row = {\"Target\": \"Total\"}\n",
    "pop_row.update(pop_summary)\n",
    "rows.append(pop_row)\n",
    "\n",
    "# For each target, compute the event count and event rate for each population group.\n",
    "for target in targets:\n",
    "    row = {\"Target\": target}\n",
    "    for group_name, X_group in populations.items():\n",
    "        # Align indices of y with this group's indices and select the target.\n",
    "        y_group = y.loc[X_group.index, target]\n",
    "        n_obs = len(y_group)\n",
    "        n_events = (y_group == 1).sum()  # Assuming an event is coded as 1\n",
    "        event_rate = (n_events / n_obs) * 100 if n_obs > 0 else 0\n",
    "        row[group_name] = f\"{n_events} ({event_rate:.1f})\"\n",
    "    rows.append(row)\n",
    "\n",
    "# Convert the list of rows to a DataFrame.\n",
    "summary_df = pd.DataFrame(rows)\n",
    "\n",
    "# Save the summary DataFrame to a CSV file.\n",
    "summary_df.to_csv(\"risk_group_distribution.csv\", index=False)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc1835-b2c4-43ea-89e5-5bc0154a9ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, accuracy_score, balanced_accuracy_score, \n",
    "    recall_score, average_precision_score, brier_score_loss\n",
    ")\n",
    "\n",
    "n_bootstraps = 1000\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "with PdfPages(\"calibration_plots.pdf\") as pdf:\n",
    "    # Iterate over each target in the targets list\n",
    "    for target in targets:\n",
    "        # Load the model from the file\n",
    "        with open(f'calibrated_model_{target}.pkl', 'rb') as file:\n",
    "            subgroup_model = pickle.load(file)\n",
    "    \n",
    "        print(f\"Evaluating performance for target: {target}\")\n",
    "        \n",
    "        # Initialize a dictionary for this target\n",
    "        results[target] = {}\n",
    "    \n",
    "        # For each population, evaluate the model\n",
    "        for group_name, X_group in populations.items():\n",
    "            y_group = y.loc[X_group.index, target]  # Align indices and select the target column\n",
    "            \n",
    "            # Ensure binary/matching targets for evaluation\n",
    "            if len(y_group.unique()) > 2:\n",
    "                print(f\"Skipping {group_name} population for target {target}: Non-binary target detected.\")\n",
    "                continue\n",
    "    \n",
    "            # Predict with the trained model\n",
    "            y_pred = subgroup_model.predict(X_group)\n",
    "            y_proba = subgroup_model.predict_proba(X_group)[:, 1]  # For AUC-ROC (probability of the positive class)\n",
    "    \n",
    "            boot_metrics = {\n",
    "            'roc_auc': [],\n",
    "            'f1': [],\n",
    "            'f1_weighted': [],\n",
    "            'accuracy': [],\n",
    "            'balanced_accuracy': [],\n",
    "            'recall_weighted': [],\n",
    "            'average_precision': [],\n",
    "            'brier_score_loss': [],\n",
    "            'calibration_slope': [],\n",
    "            'calibration_intercept': []\n",
    "        }\n",
    "            # Initialize a dictionary for this target\n",
    "            results[target][group_name] = {}\n",
    "        \n",
    "            for i in range(n_bootstraps):\n",
    "                indices = rng.choice(range(len(y_group)), size=len(y_group), replace=True)\n",
    "                y_true_bs = y_group.iloc[indices]\n",
    "                y_pred_bs = y_pred[indices]\n",
    "                y_proba_bs = y_proba[indices]\n",
    "            \n",
    "                try:\n",
    "                    boot_metrics['roc_auc'].append(roc_auc_score(y_true_bs, y_proba_bs))\n",
    "                    boot_metrics['f1'].append(f1_score(y_true_bs, y_pred_bs))\n",
    "                    boot_metrics['f1_weighted'].append(f1_score(y_true_bs, y_pred_bs, average='weighted'))\n",
    "                    boot_metrics['accuracy'].append(accuracy_score(y_true_bs, y_pred_bs))\n",
    "                    boot_metrics['balanced_accuracy'].append(balanced_accuracy_score(y_true_bs, y_pred_bs))\n",
    "                    boot_metrics['recall_weighted'].append(recall_score(y_true_bs, y_pred_bs, average='weighted'))\n",
    "                    boot_metrics['average_precision'].append(average_precision_score(y_true_bs, y_proba_bs))\n",
    "\n",
    "                    # Compute calibration slope and intercept:\n",
    "                    # Clip probabilities to avoid numeric issues with the logit transformation\n",
    "                    y_proba_bs_clipped = np.clip(y_proba_bs, 1e-15, 1-1e-15)\n",
    "                    logits = np.log(y_proba_bs_clipped / (1 - y_proba_bs_clipped))\n",
    "                    # Use linear regression (np.polyfit returns [slope, intercept] when degree=1)\n",
    "                    slope, intercept = np.polyfit(logits, y_true_bs, 1)\n",
    "                    boot_metrics['calibration_slope'].append(slope)\n",
    "                    boot_metrics['calibration_intercept'].append(intercept)\n",
    "                \n",
    "                except ValueError:\n",
    "                    # Happens if a bootstrap sample contains only one class\n",
    "                    continue\n",
    "        \n",
    "            def ci_bounds(metric_list):\n",
    "                return np.percentile(metric_list, [2.5, 97.5])\n",
    "            \n",
    "            results[target][group_name] = {}\n",
    "            \n",
    "            for metric, scores in boot_metrics.items():\n",
    "                if len(scores) > 0:\n",
    "                    mean_val = np.mean(scores)\n",
    "                    ci_low, ci_high = ci_bounds(scores)\n",
    "                    results[target][group_name][metric] = {\n",
    "                        'mean': mean_val,\n",
    "                        '95% CI': (ci_low, ci_high)\n",
    "                }\n",
    "\n",
    "             # Compute calibration curve\n",
    "            prob_true, prob_pred = calibration_curve(y_pred, y_proba, n_bins=10)\n",
    "        \n",
    "            # Plot calibration curve \n",
    "            fig, ax = plt.subplots(figsize=(7, 6))\n",
    "            ax.plot(prob_pred, prob_true, marker='o', label=\"Model Calibration\")\n",
    "            ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Perfect Calibration\")\n",
    "            ax.set_xlabel(\"Mean Predicted Probability\")\n",
    "            ax.set_ylabel(\"Fraction of Positives\")\n",
    "            ax.set_title(f\"Calibration Plot: {target}\")\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "            # Save the current figure into the PDF\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167a61b-31c4-4b04-8a74-9e8dfc71d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for target, group in results.items():\n",
    "    for group_name, metrics in group.items():\n",
    "        row = {\n",
    "            'Target': target,\n",
    "            'Subgroup': group_name\n",
    "        }\n",
    "\n",
    "        for metric_name, value in metrics.items():\n",
    "            if isinstance(value, dict) and 'mean' in value and '95% CI' in value:\n",
    "                # It's a nested dictionary with mean and confidence interval\n",
    "                row[f\"{metric_name}_mean\"] = round(value['mean'], 3)\n",
    "                row[f\"{metric_name}_ci_low\"] = round(value['95% CI'][0], 3)\n",
    "                row[f\"{metric_name}_ci_high\"] = round(value['95% CI'][1], 3)\n",
    "            elif isinstance(value, list) and len(value) == 1:\n",
    "                # Single value stored as a list\n",
    "                row[metric_name] = round(value[0], 3)\n",
    "            else:\n",
    "                # Fallback for unexpected structure\n",
    "                row[metric_name] = value\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(rows)\n",
    "\n",
    "# Display\n",
    "display(results_df)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('results_subgroups.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09cad16-90b7-4749-ab96-6ab14fdd56f7",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882e593-5fe9-43f9-8e05-d0a9a243d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting alligned with plot notebook \n",
    "\n",
    "# Set figure size and style\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "custom_target_names = {\n",
    "     'C30_PF2_class': \"Physical functioning\",\n",
    "     'C30_RF2_class': \"Role functioning\",\n",
    "     'C30_EF_class': \"Emotional functioning\",  \n",
    "     'C30_CF_class': \"Cognitive functioning\",\n",
    "     'C30_SF_class': \"Social functioning\",\n",
    "     'C30_FA_class': \"Fatigue\",\n",
    "     'C30_NV_class': \"Nausea and vomiting\",\n",
    "     'C30_PA_class': \"Pain\",\n",
    "     'C30_DY_class': \"Dyspnoea\",\n",
    "     'C30_SL_class': \"Insomnia\",\n",
    "     'C30_AP_class': \"Appetite loss\",\n",
    "     'C30_CO_class': \"Constipation\",\n",
    "     'C30_DI_class': \"Diarrhoea\",\n",
    "     'C30_FI_class': \"Financial difficulties\"\n",
    " }\n",
    "\n",
    "subgroup = ['Menopause', 'Financial difficulties', 'Obese',\n",
    "       'Comorbidities > 1', 'Lower educational status', 'Frail', 'Full external dataset'\n",
    "       ]\n",
    "\n",
    "# Force specific target order\n",
    "targets = list(custom_target_names.keys())\n",
    "custom_targets = list(custom_target_names.values())\n",
    "\n",
    "# Ensure the DataFrame is ordered according to custom target order\n",
    "results_df['Target'] = pd.Categorical(results_df['Target'], categories=targets, ordered=True)\n",
    "results_df = results_df.sort_values(['Target', 'Subgroup'])\n",
    "\n",
    "# Define bar width dynamically to prevent overlap\n",
    "num_subgroup = len(subgroup)\n",
    "bar_width = min(0.8 / num_subgroup, 0.5)  # Adjusts width for large numbers\n",
    "\n",
    "x = np.arange(len(targets))  # X positions for bars\n",
    "\n",
    "# Define colors for subgroups (options: viridis, magma, plasma, inferno)\n",
    "cmap = plt.get_cmap('plasma')  # Colormap\n",
    "colors = [cmap(i / (num_subgroup - 1)) for i in range(num_subgroup)]  # Evenly spaced colors\n",
    "\n",
    "# Plot bars with asymmetric error bars\n",
    "for i, (sg, color) in enumerate(zip(subgroup, colors)):\n",
    "    subset = results_df[results_df['Subgroup'] == sg]\n",
    "    plt.bar(\n",
    "        x + i * bar_width,\n",
    "        subset['roc_auc_mean'],\n",
    "        yerr=[\n",
    "            subset['roc_auc_mean'] - subset['roc_auc_ci_low'],  # Lower error\n",
    "            subset['roc_auc_ci_high'] - subset['roc_auc_mean']  # Upper error\n",
    "        ],\n",
    "        capsize=2,\n",
    "        width=bar_width,\n",
    "        label=sg,\n",
    "        color=color,\n",
    "        edgecolor='black',   \n",
    "        linewidth=0.5  \n",
    "    )\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"A) Model performance in risk groups\", fontsize=16, loc=\"left\")\n",
    "plt.ylabel(\"Mean ROC AUC (95% CI)\", fontsize=14)\n",
    "plt.xlabel(\"Scales\", fontsize=14)\n",
    "plt.xticks(x + (len(subgroup) - 1) * bar_width / 2, custom_targets, rotation=20, fontsize=12, ha=\"right\")  # Center tick labels\n",
    "plt.ylim(0.4, 1.0)\n",
    "plt.yticks(np.arange(0.4, 1.01, 0.1))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(title=\"Risk groups\", fontsize=10, loc='lower right', frameon=True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a9cd0b-45a4-4dce-98eb-1f033170eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting alligned with plot notebook \n",
    "\n",
    "# Set figure size and style\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "custom_target_names = {\n",
    "     'C30_PF2_class': \"Physical functioning\",\n",
    "     'C30_RF2_class': \"Role functioning\",\n",
    "     'C30_EF_class': \"Emotional functioning\",  \n",
    "     'C30_CF_class': \"Cognitive functioning\",\n",
    "     'C30_SF_class': \"Social functioning\",\n",
    "     'C30_FA_class': \"Fatigue\",\n",
    "     'C30_NV_class': \"Nausea and vomiting\",\n",
    "     'C30_PA_class': \"Pain\",\n",
    "     'C30_DY_class': \"Dyspnoea\",\n",
    "     'C30_SL_class': \"Insomnia\",\n",
    "     'C30_AP_class': \"Appetite loss\",\n",
    "     'C30_CO_class': \"Constipation\",\n",
    "     'C30_DI_class': \"Diarrhoea\",\n",
    "     'C30_FI_class': \"Financial difficulties\"\n",
    " }\n",
    "\n",
    "subgroup = ['After_diagnosis','Future_assessment', 'Full external dataset']\n",
    "#subgroup = results_df['Subgroup'].unique() # general code for any subgroups\n",
    "\n",
    "# Force specific target order\n",
    "targets = list(custom_target_names.keys())\n",
    "custom_targets = list(custom_target_names.values())\n",
    "\n",
    "# Ensure the DataFrame is ordered according to custom target order\n",
    "results_df['Target'] = pd.Categorical(results_df['Target'], categories=targets, ordered=True)\n",
    "results_df = results_df.sort_values(['Target', 'Subgroup'])\n",
    "\n",
    "# Define bar width dynamically to prevent overlap\n",
    "num_subgroup = len(subgroup)\n",
    "bar_width = min(0.8 / num_subgroup, 0.2)  # Adjusts width for large numbers\n",
    "\n",
    "x = np.arange(len(targets))  # X positions for bars\n",
    "\n",
    "# Define colors for subgroups (options: viridis, magma, plasma, inferno)\n",
    "cmap = plt.get_cmap('plasma')  # Colormap\n",
    "colors = [cmap(i / (num_subgroup - 1)) for i in range(num_subgroup)]  # Evenly spaced colors\n",
    "\n",
    "# Plot bars with asymmetric error bars\n",
    "for i, (sg, color) in enumerate(zip(subgroup, colors)):\n",
    "    subset = results_df[results_df['Subgroup'] == sg]\n",
    "    plt.bar(\n",
    "        x + i * bar_width,\n",
    "        subset['roc_auc_mean'],\n",
    "        yerr=[\n",
    "            subset['roc_auc_mean'] - subset['roc_auc_ci_low'],  # Lower error\n",
    "            subset['roc_auc_ci_high'] - subset['roc_auc_mean']  # Upper error\n",
    "        ],\n",
    "        capsize=2,\n",
    "        width=bar_width,\n",
    "        label=sg,\n",
    "        color=color,\n",
    "        edgecolor='black',   \n",
    "        linewidth=0.5  \n",
    "    )\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"B) Time dynamic performance evaluation\", fontsize=16, loc=\"left\")\n",
    "plt.ylabel(\"Mean ROC AUC (95% CI)\", fontsize=14)\n",
    "plt.xlabel(\"Scales\", fontsize=14)\n",
    "plt.xticks(x + (len(subgroup) - 1) * bar_width / 2, custom_targets, rotation=20, fontsize=12, ha=\"right\")  # Center tick labels\n",
    "plt.ylim(0.4, 1.0)\n",
    "plt.yticks(np.arange(0.4, 1.01, 0.1))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=10, loc='lower right', frameon=True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
