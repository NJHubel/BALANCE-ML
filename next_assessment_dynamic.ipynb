{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1937a-01ac-45dc-85ef-dce9d9a59f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import get_feature_sets  \n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "X = pd.read_pickle('data/cached_X_imputed.pckl')\n",
    "y = pd.read_pickle('data/cached_y.pckl')\n",
    "feature_sets = get_feature_sets(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f67743-44b3-43d2-84a1-b7ca374885ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.groupby(\"Source\").size())\n",
    "print(X.groupby(\"Source\")[\"BALANCE_ID\"].nunique())\n",
    "\n",
    "print(X.shape)\n",
    "print(X[\"BALANCE_ID\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1978a0ae-767c-4a31-b969-3bb6f5485a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# this splitter stratifies according to the \"Source\" field. \n",
    "# This means that each split should have the same distribution of values for the \"Source\" column.\n",
    "class SourceStratifiedKFold:\n",
    "    def __init__(self):\n",
    "        self.kfold = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    def split(self, df_features, df_targets, groups=None):\n",
    "        return self.kfold.split(df_features, df_features.Source, df_features.BALANCE_ID)\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.kfold.get_n_splits(X, y, groups)\n",
    "\n",
    "def validate():\n",
    "    kf = SourceStratifiedKFold()\n",
    "    for train_idx, test_idx in list(kf.split(X, y))[:1]:\n",
    "        x_train = X.iloc[train_idx]\n",
    "        x_test = X.iloc[test_idx]\n",
    "\n",
    "        y_train = y.iloc[train_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "\n",
    "        x_train_ids = set(x_train.BALANCE_ID.values)\n",
    "        x_test_ids = set(x_test.BALANCE_ID.values)\n",
    "\n",
    "        if len(x_train_ids.intersection(x_test_ids)) > 0:\n",
    "            raise Exception(\"train and test data overlap!\")\n",
    "        display(\"all good!\")\n",
    "validate()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9c747-0f94-4567-afa1-ddad0d9cdd68",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e33cc3-9df4-444d-ae86-311dcfb7fc5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, accuracy_score, balanced_accuracy_score, \n",
    "    recall_score, average_precision_score, brier_score_loss\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "model = Pipeline([\n",
    "    ('columnSelect', ColumnTransformer(\n",
    "        [\n",
    "            *[(feature, 'passthrough', [feature]) for feature in feature_sets['all'] if feature in X.columns],\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )),\n",
    "    ('scaler', None),       # Standardize the features\n",
    "    ('classifier', None)    # Base classifier  \n",
    "    \n",
    "])\n",
    "params = [\n",
    "    {\n",
    "        'classifier': [\n",
    "            ExtraTreesClassifier(random_state=42),\n",
    "            LogisticRegression(random_state=42, max_iter=1000),\n",
    "            HistGradientBoostingClassifier(random_state=42),\n",
    "            MLPClassifier(random_state=42),\n",
    "          ],\n",
    "\n",
    "         'scaler': [\n",
    "            StandardScaler(),\n",
    "            MinMaxScaler(),\n",
    "            None\n",
    "        ]\n",
    "   }\n",
    "]\n",
    "results = {}  # Initialize the results dictionary\n",
    "\n",
    "# Iterate through each target\n",
    "for target in targets:\n",
    "    display(f\"Processing target: {target}\")\n",
    "    \n",
    "    # Initialize a nested dictionary for the target\n",
    "    results[target] = {}\n",
    "\n",
    "    # Perform GridSearchCV\n",
    "    cv = GridSearchCV(\n",
    "        model, params, refit=\"roc_auc\", cv=SourceStratifiedKFold(), verbose=3, n_jobs=1,\n",
    "        scoring={'f1_weighted': 'f1_weighted', 'f1': 'f1', 'roc_auc': 'roc_auc', 'accuracy': 'accuracy',\n",
    "                 'balanced_accuracy': 'balanced_accuracy', 'recall_weighted': 'recall_weighted', 'average_precision': 'average_precision'\n",
    "                }\n",
    "    )\n",
    "    cv.fit(X, y[target])\n",
    "\n",
    "    with open(f'best_model_{target}.pkl', 'wb') as file:\n",
    "        pickle.dump(cv.best_estimator_, file)\n",
    "\n",
    "    # Save best model (before calibration)\n",
    "    best_model = cv.best_estimator_\n",
    "    \n",
    "    # Now apply post-hoc calibration\n",
    "    calibrated_model = CalibratedClassifierCV(best_model, method='sigmoid')  \n",
    "    calibrated_model.fit(X, y[target])  \n",
    "\n",
    "    with open(f'calibrated_model_{target}.pkl', 'wb') as file:\n",
    "        pickle.dump(calibrated_model, file)\n",
    "\n",
    "    # Extract classifiers used in the GridSearchCV\n",
    "    classifiers = cv.cv_results_['param_classifier']\n",
    "\n",
    "    # Extract scores for each metric and store them in the nested dictionary\n",
    "    for idx, classifier in enumerate(classifiers):\n",
    "        classifier_name = type(classifier).__name__\n",
    "\n",
    "        if classifier_name not in results[target]:\n",
    "            results[target][classifier_name] = {\n",
    "                'f1_weighted': [],\n",
    "                'f1_weighted_sd': [],\n",
    "                'f1': [],\n",
    "                'f1_sd': [],\n",
    "                'roc_auc': [],\n",
    "                'roc_auc_sd': [],\n",
    "                'accuracy': [],\n",
    "                'accuracy_sd': [],\n",
    "                'balanced_accuracy': [],\n",
    "                'balanced_accuracy_sd': [],\n",
    "                'recall_weighted': [],\n",
    "                'recall_weighted_sd': [],\n",
    "                'average_precision': [],\n",
    "                'average_precision_sd': []\n",
    "            }\n",
    "\n",
    "            # Append mean scores and standard deviations\n",
    "            results[target][classifier_name]['f1_weighted'].append(cv.cv_results_['mean_test_f1_weighted'][idx])\n",
    "            results[target][classifier_name]['f1_weighted_sd'].append(cv.cv_results_['std_test_f1_weighted'][idx])\n",
    "            \n",
    "            results[target][classifier_name]['f1'].append(cv.cv_results_['mean_test_f1'][idx])\n",
    "            results[target][classifier_name]['f1_sd'].append(cv.cv_results_['std_test_f1'][idx])\n",
    "            \n",
    "            results[target][classifier_name]['roc_auc'].append(cv.cv_results_['mean_test_roc_auc'][idx])\n",
    "            results[target][classifier_name]['roc_auc_sd'].append(cv.cv_results_['std_test_roc_auc'][idx])\n",
    "            \n",
    "            results[target][classifier_name]['accuracy'].append(cv.cv_results_['mean_test_accuracy'][idx])\n",
    "            results[target][classifier_name]['accuracy_sd'].append(cv.cv_results_['std_test_accuracy'][idx])\n",
    "            \n",
    "            results[target][classifier_name]['balanced_accuracy'].append(cv.cv_results_['mean_test_balanced_accuracy'][idx])\n",
    "            results[target][classifier_name]['balanced_accuracy_sd'].append(cv.cv_results_['std_test_balanced_accuracy'][idx])\n",
    "            \n",
    "            results[target][classifier_name]['recall_weighted'].append(cv.cv_results_['mean_test_recall_weighted'][idx])\n",
    "            results[target][classifier_name]['recall_weighted_sd'].append(cv.cv_results_['std_test_recall_weighted'][idx])\n",
    "            \n",
    "            results[target][classifier_name]['average_precision'].append(cv.cv_results_['mean_test_average_precision'][idx])\n",
    "            results[target][classifier_name]['average_precision_sd'].append(cv.cv_results_['std_test_average_precision'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bcd8d-1812-47a5-86c1-7b294d5dc9ee",
   "metadata": {},
   "source": [
    "# Storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d7912-62bb-432f-90d2-17cc3fb7e0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Flatten the results dictionary into a list of rows, with each metric as a separate column\n",
    "rows = []\n",
    "\n",
    "for target, classifiers in results.items():\n",
    "    for classifier_name, metrics in classifiers.items():\n",
    "        row = {\n",
    "            'Target': target,\n",
    "            'Classifier': classifier_name\n",
    "        }\n",
    "        # Add each metric as a column\n",
    "        for metric_name, scores in metrics.items():\n",
    "            row[metric_name] = round(np.mean(scores), 3)  # Round to 3 decimals\n",
    "        \n",
    "        rows.append(row)  # Append the row\n",
    "\n",
    "# Create a DataFrame\n",
    "results_df = pd.DataFrame(rows)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(results_df)\n",
    "\n",
    "# Export to CSV\n",
    "results_df.to_csv('results_classifier_selection.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608792f3-250a-46df-b26b-5a5bd32807ef",
   "metadata": {},
   "source": [
    "# Creating documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e8576-da5d-483f-adff-d749d85809e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list > conda_packages.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede8d7c-8bfb-4ee8-af66-56eca5097e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def inspect_pipeline_steps(targets, steps_to_print=['classifier', 'scaler']):\n",
    "    \n",
    "    # Loads multiple pipeline models from .pkl files and prints details of specific named steps.\n",
    "\n",
    "    for target in targets:\n",
    "        try:\n",
    "            # Load the model from file\n",
    "            with open(f'best_model_{target}.pkl', 'rb') as file:\n",
    "                model = pickle.load(file)\n",
    "\n",
    "            print(f\"\\n Model for target: {target}\")\n",
    "\n",
    "            # Check if the loaded object is a Pipeline\n",
    "            if not hasattr(model, \"named_steps\"):\n",
    "                print(\" Loaded model is not a Pipeline.\")\n",
    "                continue\n",
    "\n",
    "            # Loop through specified pipeline steps\n",
    "            for step in steps_to_print:\n",
    "                if step in model.named_steps:\n",
    "                    print(f\"   {step}: {model.named_steps[step]}\")\n",
    "                else:\n",
    "                    print(f\"   {step} step not found in the pipeline.\")\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f\" Model file not found: best_model_{target}.pkl\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error loading model for {target}: {e}\")\n",
    "\n",
    "inspect_pipeline_steps(targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
